---
title: "[csapp]챕터1 컴퓨터 시스템으로의 여행"
date: 2022-01-04T20:20:32Z
category: ["cs", "cs-csapp"]
tags: [csapp]
---

## **챕터1 컴퓨터 시스템으로의 여행**

---

- (컴퓨터 시스템 = 하드웨어 + 시스템 소프트웨어) => 응용프로그램 실행
- 버퍼 오버플로우 위험성으로부터 시스템을 보호해야함
- 링커 과정에서 발생하는 심각한 에러를 이해하고 회피하는 방법을 알아야함
- \+ 유닉스 쉘, 동적 메모리 할당 패키지, 웹 서버 작성, 동시성의 가능성과 위험성
- 프로세서: 메인 메모리에 저장된 바이너리 인스트럭션을 읽고 해석
- 컴퓨터가 대부분의 시간을 메모리, 입출력장치, CPU레지스터 간에 데이터를 복사하는 데 쓰고 있으므로, 저장장치들은 계층구조로 순차적으로 위치시킴
- 계층구조의 상부는 하부를 위한 캐시 역할
- 운영체제의 커널은 응용프로그램과 하드웨어 사이에서 중간다리 역할, 운영체제는 세 가지 근본적인 추상화를 제공
  1. 파일 <=> 입출력장치
  2. 가상메모리 <=> 메인 메모리와 디스크
  3. 프로세스 <=> 프로세서, 메인 메모리, 입출력 장치
- 네트워크: 컴퓨터 시스템이 서로 통신하는 방법 제공, 특정 시스템 관점으로는 네트워크 또한 하나의 입출력 장치

### **정보는 비트와 컨텍스트로 이루어진다**

---

- 텍스트 파일 : 오로지 아스키 문자들로만 이루어진 파일
- 바이너리 파일 : 텍스트 파일이 아닌 모든 파일

### **프로그램은 다른 프로그램에 의해 다른 형태로 번역된다**

---

- (전처리기 + 컴파일러 + 어셈블러 + 링커) = 컴파일 시스템

- 전처리 단계: C프로그램 수정(# 디렉티브) => .i
- 컴파일 단계: .i => .s (어셈블리어)
- 어셈블리 단계: 어셈블러가 .s => 기계어 인스트럭션 => 재배치가능 목적프로그램의 형태로 묶어서 .o라는 목적파일에 그 결과를 저장한다.
- 링크단계: 함수는 이미 컴파일된 별도의 목적파일에 들어있음. 이 파일과 다른 목적파일과 결합하기위해 링커 프로그램(ld)이 통합작업. => 결과파일은 실행파일로 메모리에 적재 => 시스템에 의해 실행

### **컴파일 시스템이 어떻게 동작하는지 이해**

---

왜?

1. 프로그램 성능 최적화: 프로그램 작성 시 올바른 판단 + 오버헤드 파악
2. 링크 에러 이해: 큰 규모의 시스템의 경우 복잡하다.(정적 변수와 전역변수 차이?, 정적 라이브러리와 동적 라이브러리 차이? 컴파일 명령 라이브러리들 순서?), 링커 에러들은 실행하기 전까지는 나타나지 않음
3. 보안 약점 피하기: 오버플로우 취약성, 비신뢰 데이터 제한 필요성, 스택 이해

### **프로세서는 메모리에 저장된 인스트럭션을 읽고 해석**

---

### **시스템의 하드웨어 조직**

---

- 버스: 시스템 내를 관통하는 배선, 컴포넌트 간 바이트 정보 전송, word(워드)라는 고정 크기의 바이트 단위로 데이터 전송
  - word의 바이트 수: 기본 시스템 변수(32, 64비트)
- 입출력 장치: 시스템과 외부세계와의 연결 담당, 입출력 버스와 컨트롤러나 어댑터를 통해 연결됨(키보드, 마우스, 디스플레이, 디스크 드라이브)
  - 컨트롤러: 디바이스 자체가 칩셋 or 머더보드
  - 어댑터: 머더보드의 슬롯에 장착된 카드
- 메인 메모리: 프로세서가 프로그램을 실행하는 동안 데이터 + 프로그램을 모두 저장하는 임시 저장 장치
  - DRAM칩들로 구성
  - 논리적으로 메모리는 연속적인 바이트들의 배열, 고유의 주소를 가짐
- 프로세서: CPU 또는 프로세서는 메인 메모리에 저장된 인스트럭션들을 실행하는 엔진, 그 중심에는 PC(program counter)
  - PC: 어느 한순간에 메인 메모리의 기계어 인스트럭션을 가리킴

#### **프로세서**

- 전원이 끊어질 때까지 프로세서는 PC가 가리키는 인스트럭션을 반복적으로 실행, PC 업데이트
- 자신의 Instruction set architecture로 정의되는 인스트럭션 실행 모델을 따라 작동
- 이 모델에서 인스트럭션은 규칙적인 순서로 실행
- 여러 단계에 걸쳐 실행
- 연속적으로 실행되는 인스트럭션들은 메모리상에서 연속적이지 않을 수 있다.
- ALU(수식/논리 처리기)주위를 순환하는 동작들
- **프로세서의 마이크로 구조와 인스트럭션 집합 구조를 구별**

### **프로그램 실행**

- 쉘 프로그램 => 자신의 인스트럭션 실행 => 명령 입력 대기 => ".\program" 입력 => 레지스터에 읽어 들임 => 메모리 저장
- 직접 메모리 접근(DMA) 기법을 이용하여 데이터는 프로세서를 거치지 않고 디스크에서 메인 메모리로 직접 이동

### **캐시의 중요성**

- 시스템은 정보를 다른 곳으로 이동시키는 일이 많음
- 이러한 이동, 즉 복사는 느리게 하는 오버헤드
- 물리학 법칙 => 더 큰 저장장치들은 작은거 보다 더 느림
- 더 빠른게 만들려면 비싸짐
- 프로세서-메모리 간 격차가 지속적으로 증가
- 메인 메모리 개발비용 > cpu 개발비용

캐시

- 프로세서와 메모리의 격차 대응
- 단기간에 필요할 정보 저장
- L1 캐시: 대략 수천 바이트
- L2 캐시: 조금 더 큼, 수백 킬로바이트~ 수 메가 바이트, 전용 버스로 연결
- L1,L2: SRAM (static randoam access memory)
- 지엽적인 영역의 코드와 데이터를 접근하는 경향인 지역성을 활용한 아이디어

### **저장장치들은 계층구조를 이룸**

![메모리 계층 구조](https://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/ComputerMemoryHierarchy.svg/300px-ComputerMemoryHierarchy.svg.png)

- 밑으로 갈 수 록 느리고 크고 싸다
- 레지스터 파일은 L0
- 아이디어: 한 레벨의 저장장치가 다음 하위레벨 저장장치의 캐시 역할

### **운영체제는 하드웨어를 관리**

- os가 제공하는 서비스를 활용
- 하드웨어와 소프트웨어 사이에 위치한 소프트웨어 계층
- os의 목적: 하드웨어의 잘못된 사용 차단, 응용프로그램들이 단순하고 균일한 메커니즘을 사용하여 저수준 hw 조작 기능

#### **프로세스: context switching**

- 실행 중인 프로그램에 대한 운영체제의 추상화
- 다수의 프로세스들은 동일한 시스템에서 동시에 실행될 수 있다.
- 즉, 한 프로세스의 인스트럭션들이 다른 프로세스의 인스트럭션들과 섞임
- 멀티코어 프로세서들 => 여러 개의 프로그램 동시에 가능
- 프로세서가 프로세스들을 바꿔주는 방식으로 한개의 CPU가 다수의 프로세스를 동시에 실행하는 것 처럼함.

문맥전환

- 교차실행 수행
- 모든 상태정보의 변화를 추적
- context: pc, 레지스터 파일, 메인 메모리의 현재 값을 포함
- 어느 한 순간에 단일 프로세서 시스템은 한 개의 프로세스의 코드만 실행 가능
- OS의 커널에 의해 관리
  - 커널: 운영체제 코드의 일부분, 메모리에 상주, 컴퓨터는 응용 프로그램의 작업요청에 대해 특정 시스템 콜을 실행하여 커널에 제어를 넘겨줌
  - 커널은 받은 작업을 수행, app으로 리턴
  - 커널은 별도의 프로세스가 아님
  - 커널은 모든 프로세스를 관리하기 위해 시스템이 이용하는 코드와 자료구조의 집합
- 프로세스의 추상화 구현
  - 저수준의 하드웨어와 os 의 긴밀한 협력 필요

### **쓰레드(Thread) : 동시성**

- 시스템에서는 프로세스가 실제로 쓰레드라고 하는 다수의 실행 유닛으로 구성되어 있다.
- 각각의 쓰레드는 해당 프로세스의 컨택스트에서 실행
- 동일한 코드와 전역 데이터를 공유
- 다수의 프로세스들에서보다 데이터의 공유가 더 쉽다
- 쓰레드가 프로세스보다 더 효울적

#### **가상 메모리**

![stack](https://drive.google.com/uc?id=1PkG5F5Q1yq4Dydj3PIdfO4TEc4n0udin)
아래가 0

- 추상화된 메모리: 각 프로세스들이 메인 메모리 전체를 독점하는 것 같이 보임

- 각 프로세스는 가상주소 공간이라는 균일한 메모리의 모습을 가짐
- 리눅스에서 주소공간의 최상위 영역은 모든 프로세스들이 공통으로 사용하는 os의 코드와 데이터를 위한 공간
- 주소공간의 하위 영역은 사용자 프로세스의 코드와 데이터를 저장
- 각 프로세스들에게 보여지는 가상주소공간은 몇 개의 정의된 영역으로 구성되어 있다.
- 가상메모리가 작동하기 위해서는 프로세서가 만들어내는 모든 주소를 하드웨어로 번역이 필요(hw <-> os 복잡한 상호작용)
  - 기본적인 아이디어: 프로세스의 가상메모리의 내용을 디스크에 저장, 메인 메모리를 디스크의 캐시로 사용

**프로그램 코드와 데이터**:

- 코드: 모든 프로세스들이 같은 고정 주소에서 시작한 후 전역변수같은 데이터 위치들이 따라옴
- 코드와 데이터 영역은 실행가능 목적파일로부터 직접 초기화

**힙**:

- 코드와 데이터 영역 (런타임 힙)
- 프로세스가 실행되면서 malloc, free 등에 의해 런타임에 동적으로 크기가 변함.

**공유 라이브러리**:

- 주소공간의 중간 부근에 표준 라이브러리와 같은 공유 라이브러리의 코드와 데이터를 저장

**스택**:

- 사용자 가상 메모리 공간의 맨 위에 컴파일러가 함수 호출을 구현하기 위해 사용하는 사용자 스택이 있음.
- 동적으로 런타임에 크기가 변함. 함수 호출 시 스택이 커짐. 함수에서 리턴시 줄어든다.

**커널 가상메모리**:

- 주소공간의 맨 윗부분은 커널을 위해 예약됨
- 응용프로그램들은 접근 금지됨
- 커널 함수 직접 호출 금지됨
- 커널을 호출해야만 접근 가능

#### **파일**

- 연속된 바이트들
- 모든 입출력장치는 파일로 모델링
- 시스템의 모든 입출력: 유닉스 io 라는 시스템 콜들 이용.
- 응용프로그램에 시스템에 들어 있는 다양한 입출력 장치들의 통일된 관점 제공(추상화: 디스크의 기술에대해 몰라도됨)

### **시스템은 네트워크를 사용하여 다른 시스템과 통신한다**

- 최신 시스템: 다른 시스템과의 연결
- 인터넷 => 다른 컴퓨터로의 정보 복사
- 일종의 입출력 장치

## **중요한 주제들**

- 시스템은 hw 그 이상의 것

### **암달의 법칙**

- 아이디어: 어떤 시스템의 한 부분의 성능을 개선할 때, 전체 시스템 성능에 대한 효과는 그 부분이 얼마나 중요한가와 이 부분이 얼마나 빨라졌는가에 관계됨.

- 전체 시스템을 빠르게 하기위해 전체 시스템의 매우 큰 부분의 성능을 개선해야 한다.

- 모든 작업을 개선하기 위한 일반적인 원칙을 설명

### **동시성과 병렬성**

- 한번에 더 많이
  | | |
  |-|-|
  |동시성| 다수가 동시에 벌어지는 일을 갖는 시스템|
  |병렬성| 동시성을 사용해 시스템을 보다 빠르게 동작하도록 하는 것, 다양한 수준의 추상화에서 활용|

- 책에선 3개의 수준 강조 (쓰레드, 인스트럭션, SIMD)

#### **쓰레드 수준 동시성**

|                          |                                                                                                                              |
| ------------------------ | ---------------------------------------------------------------------------------------------------------------------------- |
| 동시성                   | 프로세스 추상화 개념 이용 => 다수의 프로그램이 동시에 실행                                                                   |
| 쓰레드                   | 한개의 프로세스 내에 실행되는 다수의 제어흐름                                                                                |
| 시간공유 기법            | 동시 실행에 대한 지원이 컴퓨터 시스템에 나타남                                                                               |
| 단일 프로세서 시스템     | 대부분의 실질적 계산은 한 개의 프로세서에 의해 이루어짐, 다수의 태스크 전환                                                  |
| 멀티프로세서 시스템      | 여러 개의 프로세서를 가지고 하나의 os 커널의 제어 하에 동작하는 경우 (멀티코어 프로세서 + 하이퍼 쓰레딩 기법 => 일반적 환경) |
| 멀티코어 프로세서        | 여러 개의 CPU(코어)를 하나의 집적화된 칩에 내장(각각 별도의 L1, L2 캐시 사용, 메모리 인터페이스와 상위 수준 캐시 공유)       |
| 멀티쓰레딩(하이퍼쓰레딩) | 하나의 CPU가 여러 개의 제어 흐름을 실행할 수 있게 해주는 기술.                                                               |

- 기존의 프로세서는 쓰레드들 간의 전환을 약 2만 클럭 사이클이 요구되지만, 하이퍼쓰레드 프로세서에서는 매 사이클마다 실행할 쓰레드를 결정

- 멀티프로세싱으로 시스템 성능 개선
  1. 다수의 작업을 실행할 때, 동시성을 시뮬레이션할 필요를 줄여줌
  2. 멀티프로세싱으로 한 개의 응용프로그램을 빠르게 실행할 수 있음
     - 하지만, 프로그램이 병렬로 효율적으로 실행할 수 있는 멀티쓰레드의 형태로 표현되었을 때에만 가능

#### **인스트럭션 수준 병렬성**

- 여러개의 인스트럭션 한 번에 실행
- 1978년 초기: 한개의 인스트럭션 실행 약 3.1 사이클
- 최근 2010년대: 매 클럭마다 2.3개의 인스트럭션 실행
- 인스트럭션들은 시작부터 종료까지 긴 시간(20사이클 이상)이 필요하지만 여러 기법으로 한번에 100개 처리 가능
  - 파이프라인 기법: 요구되는 일들을 여러 단계로 나누고 프로세서 하드웨어가 일련의 단계로 구성되어 이들 단계를 하나씩 각각 수행, 병렬로 단계를 하나씩 수행
  - 슈퍼스케일러: 사이클당 한 개 이상의 인스트럭션을 실행할 수 있는 프로세서
    - 이 모델을 통해 작성된 코드가 보다 높은 수준의 인스트럭션 수준 병렬성을 갖게됨 (응용프로그래머들은 이 모델을 통해서 자신들이 작성한 프로그램의 성능을 이해할 수 있게됨)

#### **싱글 인스트럭션, 다중 데이터 병렬성(SIMD)**

- 최신 프로세스: 한개의 인스트럭션이 병렬로 다수의 연산을 수행할 수 있는 특수 하드웨어를 가짐
- SIMD 인스트럭션들은 보통 영상, 소리, 동영상 데이터 처리를 위한 응용프로그램의 속도를 개선하기 위해 제공된다.
- 일부 컴파일러들이 자동으로 SIMD 병렬성 사용하도록 시도 중이지만 GCC같은 컴파일러에서 지원하는 특수 데이터 타입을 사용하여 작성하는게 안정적

### **컴퓨터 시스템에서 추상화의 중요**

- 좋은 프로그래밍 연습: 함수들을 간단한 응용프로그램 인터페이스 API로 정형화
- 컴퓨터 시스템의 주요 주제는 실제 구현의 복잡성을 감추기위해 여러 수준에서 추상화하는것
- 프로세서 측면: 인스트럭션 집합구조
- 운영체제 측면: 파일 <=> 입출력 장치, 가상메모리 <=> 프로그램 메모리, 프로세스 <=> 실행 중인 프로그램
- 가상머신: 운영체제, 프로세서, 프로그램 모두를 포함하는 컴퓨터 전체의 추상화를 제공
